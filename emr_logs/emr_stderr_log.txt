Apr 12, 2024 8:37:16 PM org.apache.spark.launcher.Log4jHotPatchOption staticJavaAgentOption
WARNING: spark.log4jHotPatch.enabled is set to true, but /usr/share/log4j-cve-2021-44228-hotpatch/jdk17/Log4jHotPatchFat.jar does not exist at the configured location

24/04/12 20:37:20 INFO SparkContext: Running Spark version 3.5.0-amzn-0
24/04/12 20:37:20 INFO SparkContext: OS info Linux, 6.1.79-99.164.amzn2023.x86_64, amd64
24/04/12 20:37:20 INFO SparkContext: Java version 17.0.10
24/04/12 20:37:20 INFO ResourceUtils: ==============================================================
24/04/12 20:37:20 INFO ResourceUtils: No custom resources configured for spark.driver.
24/04/12 20:37:20 INFO ResourceUtils: ==============================================================
24/04/12 20:37:20 INFO SparkContext: Submitted application: SparkETL
24/04/12 20:37:20 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 4, script: , vendor: , memory -> name: memory, amount: 9486, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/04/12 20:37:20 INFO ResourceProfile: Limiting resource is cpus at 4 tasks per executor
24/04/12 20:37:20 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/04/12 20:37:20 INFO SecurityManager: Changing view acls to: hadoop
24/04/12 20:37:20 INFO SecurityManager: Changing modify acls to: hadoop
24/04/12 20:37:20 INFO SecurityManager: Changing view acls groups to: 
24/04/12 20:37:20 INFO SecurityManager: Changing modify acls groups to: 
24/04/12 20:37:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: hadoop; groups with view permissions: EMPTY; users with modify permissions: hadoop; groups with modify permissions: EMPTY
24/04/12 20:37:20 INFO Utils: Successfully started service 'sparkDriver' on port 37137.
24/04/12 20:37:20 INFO SparkEnv: Registering MapOutputTracker
24/04/12 20:37:20 INFO SparkEnv: Registering BlockManagerMaster
24/04/12 20:37:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/04/12 20:37:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/04/12 20:37:20 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/04/12 20:37:20 INFO DiskBlockManager: Created local directory at /mnt/tmp/blockmgr-9edeed1b-d03b-4332-8add-7664023cdd4c
24/04/12 20:37:20 INFO MemoryStore: MemoryStore started with capacity 1048.8 MiB
24/04/12 20:37:20 INFO SparkEnv: Registering OutputCommitCoordinator
24/04/12 20:37:20 INFO SubResultCacheManager: Sub-result caches are disabled.
24/04/12 20:37:21 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/04/12 20:37:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
24/04/12 20:37:21 INFO Utils: Using 50 preallocated executors (minExecutors: 0). Set spark.dynamicAllocation.preallocateExecutors to `false` disable executor preallocation.
24/04/12 20:37:21 INFO DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at ip-10-0-3-216.us-east-2.compute.internal/10.0.3.216:8032
24/04/12 20:37:21 INFO Configuration: resource-types.xml not found
24/04/12 20:37:21 INFO ResourceUtils: Unable to find 'resource-types.xml'.
24/04/12 20:37:21 INFO Client: Verifying our application has not requested more than the maximum memory capability of the cluster (12288 MB per container)
24/04/12 20:37:21 INFO Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
24/04/12 20:37:21 INFO Client: Setting up container launch context for our AM
24/04/12 20:37:21 INFO Client: Setting up the launch environment for our AM container
24/04/12 20:37:21 INFO Client: Preparing resources for our AM container
24/04/12 20:37:21 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
24/04/12 20:37:23 INFO Client: Uploading resource file:/mnt/tmp/spark-2a556373-fd26-439f-9e51-72afdff8b0f1/__spark_libs__15728579660342067712.zip -> hdfs://ip-10-0-3-216.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1712952806263_0003/__spark_libs__15728579660342067712.zip
24/04/12 20:37:24 INFO Client: Uploading resource file:/etc/spark/conf.dist/hive-site.xml -> hdfs://ip-10-0-3-216.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1712952806263_0003/hive-site.xml
24/04/12 20:37:24 INFO Client: Uploading resource file:/etc/hudi/conf.dist/hudi-defaults.conf -> hdfs://ip-10-0-3-216.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1712952806263_0003/hudi-defaults.conf
24/04/12 20:37:24 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/pyspark.zip -> hdfs://ip-10-0-3-216.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1712952806263_0003/pyspark.zip
24/04/12 20:37:24 INFO Client: Uploading resource file:/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip -> hdfs://ip-10-0-3-216.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1712952806263_0003/py4j-0.10.9.7-src.zip
24/04/12 20:37:24 INFO Client: Uploading resource file:/mnt/tmp/spark-2a556373-fd26-439f-9e51-72afdff8b0f1/__spark_conf__648608146401666037.zip -> hdfs://ip-10-0-3-216.us-east-2.compute.internal:8020/user/hadoop/.sparkStaging/application_1712952806263_0003/__spark_conf__.zip
24/04/12 20:37:24 INFO SecurityManager: Changing view acls to: hadoop
24/04/12 20:37:24 INFO SecurityManager: Changing modify acls to: hadoop
24/04/12 20:37:24 INFO SecurityManager: Changing view acls groups to: 
24/04/12 20:37:24 INFO SecurityManager: Changing modify acls groups to: 
24/04/12 20:37:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: hadoop; groups with view permissions: EMPTY; users with modify permissions: hadoop; groups with modify permissions: EMPTY
24/04/12 20:37:24 INFO Client: Submitting application application_1712952806263_0003 to ResourceManager
24/04/12 20:37:24 INFO YarnClientImpl: Submitted application application_1712952806263_0003
24/04/12 20:37:25 INFO Client: Application report for application_1712952806263_0003 (state: ACCEPTED)
24/04/12 20:37:25 INFO Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1712954244834
	 final status: UNDEFINED
	 tracking URL: http://ip-10-0-3-216.us-east-2.compute.internal:20888/proxy/application_1712952806263_0003/
	 user: hadoop
24/04/12 20:37:29 INFO Client: Application report for application_1712952806263_0003 (state: RUNNING)
24/04/12 20:37:29 INFO Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 10.0.10.172
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1712954244834
	 final status: UNDEFINED
	 tracking URL: http://ip-10-0-3-216.us-east-2.compute.internal:20888/proxy/application_1712952806263_0003/
	 user: hadoop
24/04/12 20:37:29 INFO YarnClientSchedulerBackend: Application application_1712952806263_0003 has started running.
24/04/12 20:37:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41767.
24/04/12 20:37:29 INFO NettyBlockTransferService: Server created on ip-10-0-3-216.us-east-2.compute.internal:41767
24/04/12 20:37:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/04/12 20:37:29 INFO BlockManager: external shuffle service port = 7337
24/04/12 20:37:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, ip-10-0-3-216.us-east-2.compute.internal, 41767, None)
24/04/12 20:37:29 INFO BlockManagerMasterEndpoint: Registering block manager ip-10-0-3-216.us-east-2.compute.internal:41767 with 1048.8 MiB RAM, BlockManagerId(driver, ip-10-0-3-216.us-east-2.compute.internal, 41767, None)
24/04/12 20:37:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, ip-10-0-3-216.us-east-2.compute.internal, 41767, None)
24/04/12 20:37:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, ip-10-0-3-216.us-east-2.compute.internal, 41767, None)
24/04/12 20:37:29 INFO YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> ip-10-0-3-216.us-east-2.compute.internal, PROXY_URI_BASES -> http://ip-10-0-3-216.us-east-2.compute.internal:20888/proxy/application_1712952806263_0003), /proxy/application_1712952806263_0003
24/04/12 20:37:30 INFO SingleEventLogFileWriter: Logging events to hdfs:/var/log/spark/apps/application_1712952806263_0003.inprogress
24/04/12 20:37:30 INFO Utils: Using 50 preallocated executors (minExecutors: 0). Set spark.dynamicAllocation.preallocateExecutors to `false` disable executor preallocation.
24/04/12 20:37:30 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /jobs: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /jobs/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /jobs/job: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /jobs/job/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /stages: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /stages/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /stages/stage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /stages/stage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /stages/pool: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /stages/pool/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /storage: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /storage/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /storage/rdd: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /storage/rdd/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /environment: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /environment/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /executors: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /executors/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /executors/threadDump: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /executors/threadDump/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /executors/heapHistogram: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /executors/heapHistogram/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /static: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /api: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /jobs/job/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /stages/stage/kill: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /metrics/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
24/04/12 20:37:30 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
24/04/12 20:37:30 INFO SharedState: Warehouse path is 'hdfs://ip-10-0-3-216.us-east-2.compute.internal:8020/user/spark/warehouse'.
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /SQL: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /SQL/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /SQL/execution: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /SQL/execution/json: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:30 INFO ServerInfo: Adding filter to /static/sql: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
24/04/12 20:37:31 INFO InMemoryFileIndex: It took 28 ms to list leaf files for 1 paths.
24/04/12 20:37:31 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
24/04/12 20:37:33 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.10.172:46212) with ID 2,  ResourceProfileId 0
24/04/12 20:37:33 INFO ExecutorMonitor: New executor 2 has registered (new total is 1)
24/04/12 20:37:33 INFO FileSourceStrategy: Pushed Filters: 
24/04/12 20:37:33 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
24/04/12 20:37:33 INFO BlockManagerMasterEndpoint: Registering block manager ip-10-0-10-172.us-east-2.compute.internal:39183 with 4.8 GiB RAM, BlockManagerId(2, ip-10-0-10-172.us-east-2.compute.internal, 39183, None)
24/04/12 20:37:33 INFO CodeGenerator: Code generated in 152.259114 ms
24/04/12 20:37:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 244.8 KiB, free 1048.6 MiB)
24/04/12 20:37:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 43.5 KiB, free 1048.5 MiB)
24/04/12 20:37:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ip-10-0-3-216.us-east-2.compute.internal:41767 (size: 43.5 KiB, free: 1048.8 MiB)
24/04/12 20:37:33 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
24/04/12 20:37:33 INFO GPLNativeCodeLoader: Loaded native gpl library
24/04/12 20:37:33 INFO LzoCodec: Successfully loaded & initialized native-lzo library [hadoop-lzo rev 049362b7cf53ff5f739d6b1532457f2c6cd495e8]
24/04/12 20:37:33 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false
24/04/12 20:37:33 INFO FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))
24/04/12 20:37:34 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
24/04/12 20:37:34 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/12 20:37:34 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
24/04/12 20:37:34 INFO DAGScheduler: Parents of final stage: List()
24/04/12 20:37:34 INFO DAGScheduler: Missing parents: List()
24/04/12 20:37:34 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/12 20:37:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.6 KiB, free 1048.5 MiB)
24/04/12 20:37:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 1048.5 MiB)
24/04/12 20:37:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ip-10-0-3-216.us-east-2.compute.internal:41767 (size: 8.1 KiB, free: 1048.7 MiB)
24/04/12 20:37:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1656
24/04/12 20:37:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/12 20:37:34 INFO YarnScheduler: Adding task set 0.0 with 1 tasks resource profile 0
24/04/12 20:37:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (ip-10-0-10-172.us-east-2.compute.internal, executor 2, partition 0, RACK_LOCAL, 8369 bytes) 
24/04/12 20:37:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on ip-10-0-10-172.us-east-2.compute.internal:39183 (size: 8.1 KiB, free: 4.8 GiB)
24/04/12 20:37:35 INFO YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.9.160:47826) with ID 1,  ResourceProfileId 0
24/04/12 20:37:35 INFO ExecutorMonitor: New executor 1 has registered (new total is 2)
24/04/12 20:37:35 INFO BlockManagerMasterEndpoint: Registering block manager ip-10-0-9-160.us-east-2.compute.internal:39461 with 4.8 GiB RAM, BlockManagerId(1, ip-10-0-9-160.us-east-2.compute.internal, 39461, None)
24/04/12 20:37:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on ip-10-0-10-172.us-east-2.compute.internal:39183 (size: 43.5 KiB, free: 4.8 GiB)
24/04/12 20:37:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2216 ms on ip-10-0-10-172.us-east-2.compute.internal (executor 2) (1/1)
24/04/12 20:37:36 INFO YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
24/04/12 20:37:36 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 2.370 s
24/04/12 20:37:36 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/12 20:37:36 INFO YarnScheduler: Killing all running tasks in stage 0: Stage finished
24/04/12 20:37:36 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 2.411756 s
24/04/12 20:37:36 INFO CodeGenerator: Code generated in 14.072798 ms
24/04/12 20:37:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ip-10-0-10-172.us-east-2.compute.internal:39183 in memory (size: 8.1 KiB, free: 4.8 GiB)
24/04/12 20:37:36 INFO BlockManagerInfo: Removed broadcast_1_piece0 on ip-10-0-3-216.us-east-2.compute.internal:41767 in memory (size: 8.1 KiB, free: 1048.8 MiB)
24/04/12 20:37:36 INFO FileSourceStrategy: Pushed Filters: 
24/04/12 20:37:36 INFO FileSourceStrategy: Post-Scan Filters: 
24/04/12 20:37:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 244.8 KiB, free 1048.3 MiB)
24/04/12 20:37:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 43.5 KiB, free 1048.2 MiB)
24/04/12 20:37:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ip-10-0-3-216.us-east-2.compute.internal:41767 (size: 43.5 KiB, free: 1048.7 MiB)
24/04/12 20:37:36 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
24/04/12 20:37:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false
24/04/12 20:37:36 INFO FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))
24/04/12 20:37:36 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
24/04/12 20:37:36 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/12 20:37:36 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
24/04/12 20:37:36 INFO DAGScheduler: Parents of final stage: List()
24/04/12 20:37:36 INFO DAGScheduler: Missing parents: List()
24/04/12 20:37:36 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/12 20:37:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 34.1 KiB, free 1048.2 MiB)
24/04/12 20:37:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 15.4 KiB, free 1048.2 MiB)
24/04/12 20:37:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-10-0-3-216.us-east-2.compute.internal:41767 (size: 15.4 KiB, free: 1048.7 MiB)
24/04/12 20:37:36 INFO BlockManagerInfo: Removed broadcast_0_piece0 on ip-10-0-3-216.us-east-2.compute.internal:41767 in memory (size: 43.5 KiB, free: 1048.7 MiB)
24/04/12 20:37:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1656
24/04/12 20:37:36 INFO BlockManagerInfo: Removed broadcast_0_piece0 on ip-10-0-10-172.us-east-2.compute.internal:39183 in memory (size: 43.5 KiB, free: 4.8 GiB)
24/04/12 20:37:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/12 20:37:36 INFO YarnScheduler: Adding task set 1.0 with 1 tasks resource profile 0
24/04/12 20:37:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (ip-10-0-9-160.us-east-2.compute.internal, executor 1, partition 0, RACK_LOCAL, 8369 bytes) 
24/04/12 20:37:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on ip-10-0-9-160.us-east-2.compute.internal:39461 (size: 15.4 KiB, free: 4.8 GiB)
24/04/12 20:37:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on ip-10-0-9-160.us-east-2.compute.internal:39461 (size: 43.5 KiB, free: 4.8 GiB)
24/04/12 20:37:40 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3306 ms on ip-10-0-9-160.us-east-2.compute.internal (executor 1) (1/1)
24/04/12 20:37:40 INFO YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
24/04/12 20:37:40 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 3.348 s
24/04/12 20:37:40 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/12 20:37:40 INFO YarnScheduler: Killing all running tasks in stage 1: Stage finished
24/04/12 20:37:40 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 3.355107 s
24/04/12 20:37:40 INFO FileSourceStrategy: Pushed Filters: 
24/04/12 20:37:40 INFO FileSourceStrategy: Post-Scan Filters: 
24/04/12 20:37:40 INFO CodeGenerator: Code generated in 41.036133 ms
24/04/12 20:37:40 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 244.7 KiB, free 1048.2 MiB)
24/04/12 20:37:40 INFO BlockManagerInfo: Removed broadcast_3_piece0 on ip-10-0-3-216.us-east-2.compute.internal:41767 in memory (size: 15.4 KiB, free: 1048.8 MiB)
24/04/12 20:37:40 INFO BlockManagerInfo: Removed broadcast_3_piece0 on ip-10-0-9-160.us-east-2.compute.internal:39461 in memory (size: 15.4 KiB, free: 4.8 GiB)
24/04/12 20:37:40 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 43.5 KiB, free 1048.2 MiB)
24/04/12 20:37:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ip-10-0-3-216.us-east-2.compute.internal:41767 (size: 43.5 KiB, free: 1048.7 MiB)
24/04/12 20:37:40 INFO SparkContext: Created broadcast 4 from showString at NativeMethodAccessorImpl.java:0
24/04/12 20:37:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false
24/04/12 20:37:40 INFO FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))
24/04/12 20:37:40 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
24/04/12 20:37:40 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/12 20:37:40 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)
24/04/12 20:37:40 INFO DAGScheduler: Parents of final stage: List()
24/04/12 20:37:40 INFO DAGScheduler: Missing parents: List()
24/04/12 20:37:40 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/12 20:37:40 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 28.7 KiB, free 1048.2 MiB)
24/04/12 20:37:40 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 11.5 KiB, free 1048.2 MiB)
24/04/12 20:37:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ip-10-0-3-216.us-east-2.compute.internal:41767 (size: 11.5 KiB, free: 1048.7 MiB)
24/04/12 20:37:40 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1656
24/04/12 20:37:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/12 20:37:40 INFO YarnScheduler: Adding task set 2.0 with 1 tasks resource profile 0
24/04/12 20:37:40 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (ip-10-0-9-160.us-east-2.compute.internal, executor 1, partition 0, RACK_LOCAL, 8369 bytes) 
24/04/12 20:37:40 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on ip-10-0-9-160.us-east-2.compute.internal:39461 (size: 11.5 KiB, free: 4.8 GiB)
24/04/12 20:37:40 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on ip-10-0-9-160.us-east-2.compute.internal:39461 (size: 43.5 KiB, free: 4.8 GiB)
24/04/12 20:37:40 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 319 ms on ip-10-0-9-160.us-east-2.compute.internal (executor 1) (1/1)
24/04/12 20:37:40 INFO YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
24/04/12 20:37:40 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 0.333 s
24/04/12 20:37:40 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/12 20:37:40 INFO YarnScheduler: Killing all running tasks in stage 2: Stage finished
24/04/12 20:37:40 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0.339583 s
24/04/12 20:37:40 INFO CodeGenerator: Code generated in 41.085259 ms
24/04/12 20:37:40 INFO FileSourceStrategy: Pushed Filters: 
24/04/12 20:37:40 INFO FileSourceStrategy: Post-Scan Filters: 
24/04/12 20:37:41 INFO CodeGenerator: Code generated in 17.93933 ms
24/04/12 20:37:41 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 244.7 KiB, free 1048.0 MiB)
24/04/12 20:37:41 INFO BlockManagerInfo: Removed broadcast_5_piece0 on ip-10-0-3-216.us-east-2.compute.internal:41767 in memory (size: 11.5 KiB, free: 1048.7 MiB)
24/04/12 20:37:41 INFO BlockManagerInfo: Removed broadcast_5_piece0 on ip-10-0-9-160.us-east-2.compute.internal:39461 in memory (size: 11.5 KiB, free: 4.8 GiB)
24/04/12 20:37:41 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 43.5 KiB, free 1048.0 MiB)
24/04/12 20:37:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on ip-10-0-3-216.us-east-2.compute.internal:41767 (size: 43.5 KiB, free: 1048.7 MiB)
24/04/12 20:37:41 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
24/04/12 20:37:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false
24/04/12 20:37:41 INFO FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))
24/04/12 20:37:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ip-10-0-9-160.us-east-2.compute.internal:39461 in memory (size: 43.5 KiB, free: 4.8 GiB)
24/04/12 20:37:41 INFO BlockManagerInfo: Removed broadcast_2_piece0 on ip-10-0-3-216.us-east-2.compute.internal:41767 in memory (size: 43.5 KiB, free: 1048.7 MiB)
24/04/12 20:37:41 INFO BlockManagerInfo: Removed broadcast_4_piece0 on ip-10-0-3-216.us-east-2.compute.internal:41767 in memory (size: 43.5 KiB, free: 1048.8 MiB)
24/04/12 20:37:41 INFO BlockManagerInfo: Removed broadcast_4_piece0 on ip-10-0-9-160.us-east-2.compute.internal:39461 in memory (size: 43.5 KiB, free: 4.8 GiB)
24/04/12 20:37:41 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
24/04/12 20:37:41 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/12 20:37:41 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
24/04/12 20:37:41 INFO DAGScheduler: Parents of final stage: List()
24/04/12 20:37:41 INFO DAGScheduler: Missing parents: List()
24/04/12 20:37:41 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/12 20:37:41 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 21.5 KiB, free 1048.5 MiB)
24/04/12 20:37:41 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 1048.5 MiB)
24/04/12 20:37:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on ip-10-0-3-216.us-east-2.compute.internal:41767 (size: 10.7 KiB, free: 1048.7 MiB)
24/04/12 20:37:41 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1656
24/04/12 20:37:41 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/12 20:37:41 INFO YarnScheduler: Adding task set 3.0 with 1 tasks resource profile 0
24/04/12 20:37:41 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (ip-10-0-10-172.us-east-2.compute.internal, executor 2, partition 0, RACK_LOCAL, 8358 bytes) 
24/04/12 20:37:41 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on ip-10-0-10-172.us-east-2.compute.internal:39183 (size: 10.7 KiB, free: 4.8 GiB)
24/04/12 20:37:41 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on ip-10-0-10-172.us-east-2.compute.internal:39183 (size: 43.5 KiB, free: 4.8 GiB)
24/04/12 20:37:41 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 455 ms on ip-10-0-10-172.us-east-2.compute.internal (executor 2) (1/1)
24/04/12 20:37:41 INFO YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
24/04/12 20:37:41 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.480 s
24/04/12 20:37:41 INFO DAGScheduler: looking for newly runnable stages
24/04/12 20:37:41 INFO DAGScheduler: running: Set()
24/04/12 20:37:41 INFO DAGScheduler: waiting: Set()
24/04/12 20:37:41 INFO DAGScheduler: failed: Set()
24/04/12 20:37:41 INFO CodeGenerator: Code generated in 11.471425 ms
24/04/12 20:37:41 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
24/04/12 20:37:41 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/12 20:37:41 INFO DAGScheduler: Final stage: ResultStage 5 (count at NativeMethodAccessorImpl.java:0)
24/04/12 20:37:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
24/04/12 20:37:41 INFO DAGScheduler: Missing parents: List()
24/04/12 20:37:41 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/12 20:37:41 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 13.5 KiB, free 1048.5 MiB)
24/04/12 20:37:41 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.5 KiB, free 1048.5 MiB)
24/04/12 20:37:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on ip-10-0-3-216.us-east-2.compute.internal:41767 (size: 6.5 KiB, free: 1048.7 MiB)
24/04/12 20:37:41 INFO BlockManagerInfo: Removed broadcast_7_piece0 on ip-10-0-3-216.us-east-2.compute.internal:41767 in memory (size: 10.7 KiB, free: 1048.8 MiB)
24/04/12 20:37:41 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1656
24/04/12 20:37:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/12 20:37:41 INFO YarnScheduler: Adding task set 5.0 with 1 tasks resource profile 0
24/04/12 20:37:41 INFO BlockManagerInfo: Removed broadcast_7_piece0 on ip-10-0-10-172.us-east-2.compute.internal:39183 in memory (size: 10.7 KiB, free: 4.8 GiB)
24/04/12 20:37:41 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (ip-10-0-10-172.us-east-2.compute.internal, executor 2, partition 0, NODE_LOCAL, 7626 bytes) 
24/04/12 20:37:41 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on ip-10-0-10-172.us-east-2.compute.internal:39183 (size: 6.5 KiB, free: 4.8 GiB)
24/04/12 20:37:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 10.0.10.172:46212
24/04/12 20:37:41 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 131 ms on ip-10-0-10-172.us-east-2.compute.internal (executor 2) (1/1)
24/04/12 20:37:41 INFO YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
24/04/12 20:37:41 INFO DAGScheduler: ResultStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0.147 s
24/04/12 20:37:41 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/12 20:37:41 INFO YarnScheduler: Killing all running tasks in stage 5: Stage finished
24/04/12 20:37:41 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.157768 s
24/04/12 20:37:41 INFO FileSourceStrategy: Pushed Filters: 
24/04/12 20:37:41 INFO FileSourceStrategy: Post-Scan Filters: 
24/04/12 20:37:42 INFO ParquetUtils: Using user defined output committer for Parquet: com.amazon.emr.committer.EmrOptimizedSparkSqlParquetOutputCommitter
24/04/12 20:37:42 INFO SQLConfCommitterProvider: Getting user defined output committer class com.amazon.emr.committer.EmrOptimizedSparkSqlParquetOutputCommitter
24/04/12 20:37:42 INFO EmrOptimizedParquetOutputCommitter: EMR Optimized Committer: ENABLED
24/04/12 20:37:42 INFO EmrOptimizedParquetOutputCommitter: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileSystemOptimizedCommitter
24/04/12 20:37:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
24/04/12 20:37:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: true
24/04/12 20:37:42 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
24/04/12 20:37:42 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: true
24/04/12 20:37:42 INFO SQLConfCommitterProvider: Using output committer class com.amazon.emr.committer.EmrOptimizedSparkSqlParquetOutputCommitter
24/04/12 20:37:42 INFO FileSystemOptimizedCommitter: Nothing to setup as successful task attempt outputs are written directly
24/04/12 20:37:42 INFO CodeGenerator: Code generated in 16.682455 ms
24/04/12 20:37:42 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 244.7 KiB, free 1048.3 MiB)
24/04/12 20:37:42 INFO BlockManagerInfo: Removed broadcast_6_piece0 on ip-10-0-10-172.us-east-2.compute.internal:39183 in memory (size: 43.5 KiB, free: 4.8 GiB)
24/04/12 20:37:42 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 43.5 KiB, free 1048.2 MiB)
24/04/12 20:37:42 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on ip-10-0-3-216.us-east-2.compute.internal:41767 (size: 43.5 KiB, free: 1048.7 MiB)
24/04/12 20:37:42 INFO SparkContext: Created broadcast 9 from parquet at NativeMethodAccessorImpl.java:0
24/04/12 20:37:42 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes, number of split files: 1, prefetch: false
24/04/12 20:37:42 INFO FileSourceScanExec: relation: None, fileSplitsInPartitionHistogram: Vector((1 fileSplits,1))
24/04/12 20:37:42 INFO BlockManagerInfo: Removed broadcast_6_piece0 on ip-10-0-3-216.us-east-2.compute.internal:41767 in memory (size: 43.5 KiB, free: 1048.8 MiB)
24/04/12 20:37:42 INFO BlockManagerInfo: Removed broadcast_8_piece0 on ip-10-0-3-216.us-east-2.compute.internal:41767 in memory (size: 6.5 KiB, free: 1048.8 MiB)
24/04/12 20:37:42 INFO BlockManagerInfo: Removed broadcast_8_piece0 on ip-10-0-10-172.us-east-2.compute.internal:39183 in memory (size: 6.5 KiB, free: 4.8 GiB)
24/04/12 20:37:42 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
24/04/12 20:37:42 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
24/04/12 20:37:42 INFO DAGScheduler: Final stage: ResultStage 6 (parquet at NativeMethodAccessorImpl.java:0)
24/04/12 20:37:42 INFO DAGScheduler: Parents of final stage: List()
24/04/12 20:37:42 INFO DAGScheduler: Missing parents: List()
24/04/12 20:37:42 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[24] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
24/04/12 20:37:42 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 268.5 KiB, free 1048.3 MiB)
24/04/12 20:37:42 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 101.0 KiB, free 1048.2 MiB)
24/04/12 20:37:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on ip-10-0-3-216.us-east-2.compute.internal:41767 (size: 101.0 KiB, free: 1048.7 MiB)
24/04/12 20:37:42 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1656
24/04/12 20:37:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[24] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
24/04/12 20:37:42 INFO YarnScheduler: Adding task set 6.0 with 1 tasks resource profile 0
24/04/12 20:37:42 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 5) (ip-10-0-10-172.us-east-2.compute.internal, executor 2, partition 0, RACK_LOCAL, 8369 bytes) 
24/04/12 20:37:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on ip-10-0-10-172.us-east-2.compute.internal:39183 (size: 101.0 KiB, free: 4.8 GiB)
24/04/12 20:37:42 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on ip-10-0-10-172.us-east-2.compute.internal:39183 (size: 43.5 KiB, free: 4.8 GiB)
24/04/12 20:37:44 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 5) in 1862 ms on ip-10-0-10-172.us-east-2.compute.internal (executor 2) (1/1)
24/04/12 20:37:44 INFO YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
24/04/12 20:37:44 INFO DAGScheduler: ResultStage 6 (parquet at NativeMethodAccessorImpl.java:0) finished in 1.905 s
24/04/12 20:37:44 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
24/04/12 20:37:44 INFO YarnScheduler: Killing all running tasks in stage 6: Stage finished
24/04/12 20:37:44 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 1.911064 s
24/04/12 20:37:44 INFO FileFormatWriter: Start to commit write Job 4a596f46-d518-4ede-92f3-198144c104a0.
24/04/12 20:37:44 INFO MultipartUploadOutputStream: close closed:false s3://emr-master/outputs/tripdata/_SUCCESS
24/04/12 20:37:44 INFO FileFormatWriter: Write Job 4a596f46-d518-4ede-92f3-198144c104a0 committed. Elapsed time: 155 ms.
24/04/12 20:37:44 INFO FileFormatWriter: Finished processing stats for write job 4a596f46-d518-4ede-92f3-198144c104a0.
24/04/12 20:37:44 INFO SparkContext: Invoking stop() from shutdown hook
24/04/12 20:37:44 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/04/12 20:37:44 INFO SparkUI: Stopped Spark web UI at http://ip-10-0-3-216.us-east-2.compute.internal:4040
24/04/12 20:37:44 INFO YarnClientSchedulerBackend: Interrupting monitor thread
24/04/12 20:37:44 INFO YarnClientSchedulerBackend: Shutting down all executors
24/04/12 20:37:44 INFO YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
24/04/12 20:37:44 INFO YarnClientSchedulerBackend: YARN client scheduler backend Stopped
24/04/12 20:37:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/04/12 20:37:44 INFO MemoryStore: MemoryStore cleared
24/04/12 20:37:44 INFO BlockManager: BlockManager stopped
24/04/12 20:37:44 INFO BlockManagerMaster: BlockManagerMaster stopped
24/04/12 20:37:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/04/12 20:37:44 INFO SparkContext: Successfully stopped SparkContext
24/04/12 20:37:44 INFO ShutdownHookManager: Shutdown hook called
24/04/12 20:37:44 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-2a556373-fd26-439f-9e51-72afdff8b0f1
24/04/12 20:37:44 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-1b1b56a8-28cc-40b0-8e12-c14432a45146
24/04/12 20:37:44 INFO ShutdownHookManager: Deleting directory /mnt/tmp/spark-2a556373-fd26-439f-9e51-72afdff8b0f1/pyspark-1fe3b65b-470f-4507-b24d-b44f176679cf
Command exiting with ret '0'
